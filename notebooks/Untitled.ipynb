{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "63e81e2d-04cd-4b27-9d95-b0431183cd38",
   "metadata": {},
   "outputs": [],
   "source": [
    "import h5py\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import re\n",
    "from collections import defaultdict\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from ipywidgets import interact, Dropdown, FloatSlider, IntSlider"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0562c1e1-1094-4b4e-968e-27fb0f0d5660",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error reading CFA6_2.4.20_contra3_0um_cor_df_f_traces.h5: \"Unable to synchronously open object (object 'data' doesn't exist)\"\n",
      "Error reading CFA7_2.5.20_contra3_0um_cor_df_f_traces.h5: \"Unable to synchronously open object (object 'data' doesn't exist)\"\n",
      "Error reading CFA7_2.5.20_ipsi1_0um_cor_df_f_traces.h5: \"Unable to synchronously open object (object 'data' doesn't exist)\"\n",
      "Error reading CFA7_2.5.20_ipsi2_0um_cor_df_f_traces.h5: \"Unable to synchronously open object (object 'data' doesn't exist)\"\n",
      "Error reading Disinhib3_7.29.20_ipsi2_0um_cor_df_f_traces.h5: \"Unable to synchronously open object (object 'data' doesn't exist)\"\n",
      "Error reading Disinhib4_8.4.20_ipsi2_0um_cor_df_f_traces.h5: \"Unable to synchronously open object (object 'data' doesn't exist)\"\n",
      "Error reading Disinhib7_1.27.21_contra2_0um_cor_df_f_traces.h5: \"Unable to synchronously open object (object 'data' doesn't exist)\"\n",
      "Error reading Disinhib7_1.27.21_contra3_0um_cor_df_f_traces.h5: \"Unable to synchronously open object (object 'data' doesn't exist)\"\n",
      "Error reading SNI4_10.2.19_ipsi2_0um_cor_df_f_traces.h5: \"Unable to synchronously open object (object 'data' doesn't exist)\"\n",
      "Error reading SNI5_10.9.19_contra2_0um_cor_df_f_traces.h5: \"Unable to synchronously open object (object 'data' doesn't exist)\"\n",
      "Error reading SNI5_10.9.19_contra3_0um_cor_df_f_traces.h5: \"Unable to synchronously open object (object 'data' doesn't exist)\"\n",
      "Error reading SNI5_10.9.19_ipsi1_0um_cor_df_f_traces.h5: \"Unable to synchronously open object (object 'data' doesn't exist)\"\n",
      "Data loaded and organized.\n"
     ]
    }
   ],
   "source": [
    "# --- 1. Load Data and Organize ---\n",
    "data = defaultdict(lambda: defaultdict(list))\n",
    "file_dir = \"F:/Recovered/Research/BoninLab/PainModelingProject/ForCumin/0um_h5/test_subset\"  # Replace with the actual path\n",
    "\n",
    "for filename in os.listdir(file_dir):\n",
    "    if filename.endswith('.h5') and 'df_f_traces' in filename:\n",
    "        match = re.search(r'(Cap|CFA|SNI|Sham|Disinhib|OA|Paclitaxel)(\\d+)_(\\d+\\.\\d+\\.\\d+)_([a-z]+)(\\d+)', filename)\n",
    "        if match:\n",
    "            model = match.group(1)\n",
    "            side = 'ipsi' if 'ipsi' in filename else 'contra'\n",
    "            try:\n",
    "                with h5py.File(os.path.join(file_dir, filename), 'r') as f:\n",
    "                    traces = np.array(f['data'])\n",
    "                    data[model][side].append(traces)\n",
    "            except Exception as e:\n",
    "                print(f\"Error reading {filename}: {e}\")\n",
    "\n",
    "print(\"Data loaded and organized.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "05f2450f-e627-48da-8088-380c732ac165",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e8577b98d3364a5d83a5d7da9fd7e83e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(FloatSlider(value=0.5, description='Event Threshold', max=2.0, min=0.1, step=0.01), Outp…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adjust the threshold slider above to detect events.\n"
     ]
    }
   ],
   "source": [
    "# --- 2. Event Detection with Interactive Threshold ---\n",
    "event_data = defaultdict(lambda: defaultdict(lambda: defaultdict(list)))\n",
    "\n",
    "def interactive_event_detection(threshold):\n",
    "    event_data.clear()  # Clear previous results\n",
    "    for model, sides in data.items():\n",
    "        for side, all_traces in sides.items():\n",
    "            for slice_traces in all_traces:\n",
    "                events_per_roi = [detect_events(trace, threshold=threshold) for trace in slice_traces]\n",
    "                event_data[model][side].append(events_per_roi)\n",
    "    print(f\"Events detected with threshold: {threshold}\")\n",
    "    return event_data\n",
    "\n",
    "@interact(threshold=FloatSlider(min=0.1, max=2.0, step=0.01, value=0.5, description='Event Threshold'))\n",
    "def run_event_detection(threshold):\n",
    "    global event_data\n",
    "    event_data = interactive_event_detection(threshold)\n",
    "    # Optionally, you could trigger the subsequent analyses here if you want to see results update with the threshold\n",
    "\n",
    "# Placeholder for a message after interactive detection\n",
    "print(\"Adjust the threshold slider above to detect events.\")\n",
    "\n",
    "def detect_events(trace, threshold=0.5):\n",
    "    \"\"\"Detects events based on a simple amplitude threshold.\"\"\"\n",
    "    return np.where(trace > threshold)[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b0cbe67a-da3e-401d-88a5-22082a153041",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ad9f0c2d0a174472b9f9c71ee184219f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(IntSlider(value=10, description='Co-occurrence Window', max=50, min=1), Output()), _dom_…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# --- 3. Co-occurrence Analysis ---\n",
    "co_occurrence_results = defaultdict(lambda: defaultdict(list))\n",
    "\n",
    "def calculate_co_occurrence(events1, events2, window=10):\n",
    "    co_occurrences = 0\n",
    "    for e1 in events1:\n",
    "        for e2 in events2:\n",
    "            if abs(e1 - e2) <= window:\n",
    "                co_occurrences += 1\n",
    "    return co_occurrences\n",
    "\n",
    "def run_co_occurrence_analysis(event_data, window=10):\n",
    "    co_occurrence_results.clear()\n",
    "    for model, sides in event_data.items():\n",
    "        for side, all_slices_events in sides.items():\n",
    "            for slice_events in all_slices_events:\n",
    "                num_rois = len(slice_events)\n",
    "                co_occurrence_matrix = np.zeros((num_rois, num_rois))\n",
    "                for i in range(num_rois):\n",
    "                    for j in range(i + 1, num_rois):\n",
    "                        co_occurrences = calculate_co_occurrence(slice_events[i], slice_events[j], window=window)\n",
    "                        co_occurrence_matrix[i, j] = co_occurrences\n",
    "                        co_occurrence_matrix[j, i] = co_occurrences\n",
    "                co_occurrence_results[model][side].append(co_occurrence_matrix)\n",
    "    print(f\"Co-occurrence matrices calculated with window: {window}\")\n",
    "    return co_occurrence_results\n",
    "\n",
    "@interact(window=IntSlider(min=1, max=50, step=1, value=10, description='Co-occurrence Window'))\n",
    "def visualize_co_occurrence(window):\n",
    "    if event_data:\n",
    "        co_occurrence_results = run_co_occurrence_analysis(event_data, window)\n",
    "        plot_connectivity_distributions(co_occurrence_results, f'Distribution of Co-occurrence (Pairwise, Window={window})')\n",
    "    else:\n",
    "        print(\"Please run event detection first.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "18f8e60f-62e8-44f0-96e8-ab53eb93d271",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "126e1fb2a35b45439f76e4416700a0f8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(FloatSlider(value=0.5, description='Threshold for Binarization', max=2.0, min=0.1), IntS…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# --- 4. Cross-Correlation Analysis ---\n",
    "cross_correlation_results = defaultdict(lambda: defaultdict(list))\n",
    "\n",
    "def binarize_trace(trace, threshold):\n",
    "    return (trace > threshold).astype(int)\n",
    "\n",
    "def calculate_peak_cross_correlation(trace1_bin, trace2_bin, max_lag=50):\n",
    "    corr = np.correlate(trace1_bin, trace2_bin, mode='same')\n",
    "    lags = np.arange(-len(trace1_bin) + 1, len(trace1_bin))\n",
    "    zero_lag_index = np.where(lags == 0)[0][0]\n",
    "    corr_without_zero = np.concatenate((corr[:zero_lag_index], corr[zero_lag_index+1:]))\n",
    "    if corr_without_zero.size > 0:\n",
    "        return np.max(np.abs(corr_without_zero)) / np.sqrt(np.sum(trace1_bin) * np.sum(trace2_bin)) if (np.sum(trace1_bin) > 0 and np.sum(trace2_bin) > 0) else 0\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "def run_cross_correlation_analysis(data, threshold, max_lag=50):\n",
    "    cross_correlation_results.clear()\n",
    "    for model, sides in data.items():\n",
    "        for side, all_traces in sides.items():\n",
    "            for slice_traces in all_traces:\n",
    "                num_rois = len(slice_traces)\n",
    "                peak_corr_matrix = np.zeros((num_rois, num_rois))\n",
    "                binarized_traces = [binarize_trace(trace, threshold) for trace in slice_traces]\n",
    "                for i in range(num_rois):\n",
    "                    for j in range(i + 1, num_rois):\n",
    "                        peak_corr = calculate_peak_cross_correlation(binarized_traces[i], binarized_traces[j], max_lag=max_lag)\n",
    "                        peak_corr_matrix[i, j] = peak_corr\n",
    "                        peak_corr_matrix[j, i] = peak_corr\n",
    "                cross_correlation_results[model][side].append(peak_corr_matrix)\n",
    "    print(f\"Peak cross-correlation matrices calculated with threshold: {threshold}, max_lag: {max_lag}\")\n",
    "    return cross_correlation_results\n",
    "\n",
    "@interact(threshold=FloatSlider(min=0.1, max=2.0, step=0.1, value=0.5, description='Threshold for Binarization'),\n",
    "          max_lag=IntSlider(min=10, max=200, step=10, value=50, description='Max Lag'))\n",
    "def visualize_cross_correlation(threshold, max_lag):\n",
    "    cross_correlation_results = run_cross_correlation_analysis(data, threshold, max_lag)\n",
    "    plot_connectivity_distributions(cross_correlation_results, f'Distribution of Peak Cross-Correlation (Pairwise, Threshold={threshold}, Max Lag={max_lag})')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f0e41fc2-ee75-497c-a62c-f276f598db3d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ready for interactive analysis and visualization!\n",
      "Adjust the sliders to explore different parameters.\n"
     ]
    }
   ],
   "source": [
    "# --- 5. Visualization Function ---\n",
    "def plot_connectivity_distributions(results, title):\n",
    "    data_to_plot = []\n",
    "    for model, sides in results.items():\n",
    "        for side, all_matrices in sides.items():\n",
    "            for matrix in all_matrices:\n",
    "                upper_triangle = matrix[np.triu_indices_from(matrix, k=1)]\n",
    "                df = pd.DataFrame({'value': upper_triangle, 'model': model, 'side': side})\n",
    "                data_to_plot.append(df)\n",
    "\n",
    "    if data_to_plot:\n",
    "        combined_df = pd.concat(data_to_plot)\n",
    "        plt.figure(figsize=(12, 6))\n",
    "        sns.boxplot(x='model', y='value', hue='side', data=combined_df)\n",
    "        plt.title(title)\n",
    "        plt.ylabel('Connectivity Strength')\n",
    "        plt.xlabel('Pain Model')\n",
    "        plt.xticks(rotation=45, ha='right')\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "    else:\n",
    "        print(\"No data to plot.\")\n",
    "\n",
    "from ipywidgets import IntSlider\n",
    "\n",
    "# Add an interactive slider for the co-occurrence window\n",
    "\n",
    "print(\"Ready for interactive analysis and visualization!\")\n",
    "print(\"Adjust the sliders to explore different parameters.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa5c22a5-d430-4268-829a-f49ce04199fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import stats\n",
    "import pandas as pd\n",
    "import statsmodels.api as sa\n",
    "from statsmodels.formula.api import ols\n",
    "from statsmodels.stats.multicomp import pairwise_tukeyhsd\n",
    "\n",
    "def calculate_summary_metric(matrix, metric='mean'):\n",
    "    \"\"\"Calculates a summary metric from the connectivity matrix.\"\"\"\n",
    "    upper_triangle = matrix[np.triu_indices_from(matrix, k=1)]\n",
    "    if metric == 'mean':\n",
    "        return np.mean(upper_triangle)\n",
    "    elif metric == 'max':\n",
    "        return np.max(upper_triangle)\n",
    "    # Add other metrics as needed\n",
    "\n",
    "summary_results_cooc = defaultdict(lambda: defaultdict(list))\n",
    "for model, sides in co_occurrence_results.items():\n",
    "    for side, all_matrices in sides.items():\n",
    "        for matrix in all_matrices:\n",
    "            summary_results_cooc[model][side].append(calculate_summary_metric(matrix))\n",
    "\n",
    "summary_results_corr = defaultdict(lambda: defaultdict(list))\n",
    "for model, sides in cross_correlation_results.items():\n",
    "    for side, all_matrices in sides.items():\n",
    "        for matrix in all_matrices:\n",
    "            summary_results_corr[model][side].append(calculate_summary_metric(matrix))\n",
    "\n",
    "# Example: Comparing mean co-occurrence between Sham and CFA (ipsi)\n",
    "sham_ipsi_cooc = summary_results_cooc['Sham']['ipsi']\n",
    "cfa_ipsi_cooc = summary_results_cooc['CFA']['ipsi']\n",
    "if sham_ipsi_cooc and cfa_ipsi_cooc:\n",
    "    t_stat, p_val = stats.ttest_ind(sham_ipsi_cooc, cfa_ipsi_cooc)\n",
    "    print(f\"T-test (Sham-ipsi vs. CFA-ipsi) for mean co-occurrence: t={t_stat:.3f}, p={p_val:.3f}\")\n",
    "\n",
    "# Example: ANOVA for mean cross-correlation across all ipsi models\n",
    "data_anova = []\n",
    "for model, sides in summary_results_corr.items():\n",
    "    if 'ipsi' in sides:\n",
    "        for value in sides['ipsi']:\n",
    "            data_anova.append({'value': value, 'model': model})\n",
    "df_anova = pd.DataFrame(data_anova)\n",
    "\n",
    "if not df_anova.empty:\n",
    "    model_anova = ols('value ~ C(model)', data=df_anova).fit()\n",
    "    anova_table = sa.stats.anova_lm(model_anova)\n",
    "    print(\"\\nANOVA for mean cross-correlation (ipsi):\")\n",
    "    print(anova_table)\n",
    "\n",
    "    # Post-hoc test (Tukey's HSD) if ANOVA is significant\n",
    "    if anova_table['PR(>F)'][0] < 0.05:\n",
    "        m_comp = pairwise_tukeyhsd(endog=df_anova['value'], groups=df_anova['model'], alpha=0.05)\n",
    "        print(\"\\nTukey's HSD Post-hoc Test:\")\n",
    "        print(m_comp)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
